\section{Experiments}\label{sec:experiments}

TODO introduction

\subsection{Setup}

We run our experiments on machines of the type \texttt{diamond} of the Scilens cluster owned by the CWI Database Architecture research
group.
These machines feature 4 Intel Xeon E5-4657Lv2 processors with 12 cores each and hyperthreading of 2 (48 cores / 96 threads)
Each core has 32 KB of 1st level cache, 32KB 2nd level cache.
The 3rd level cache are 30 MB shared between 12 cores.
The main memory consists of 1 TB of RAM DDR-3 memory.

The machines run a Fedora version 30 Linux system with the 5.0.17-300.fc30.x86\_64 kernel.
We use Spark 2.4.0 with Scala 2.11.12 on Java openJDK 1.8.
In the majority of our experiments, we use Spark in its standard configuration with enabled code generation.
We also tune the parameters for driver and executor memory usage (\texttt{spark.driver.memory} and \texttt{spark.executor.memory}) to fit
all necessary data into main memory.

\subsubsection{Algorithms}

In our experiments we use 4 different join algorithms.
Two of them are worst-case optimal joins.
That is our Leapfrog Triejoin implementation and a graph-pattern matching
specialized Leapfrog Triejoin developed in this thesis: Graph\textsc{WCOJ}.
LFTJ is only run as sequential algorithm as a baseline against GraphWCOJ.
We compare these two algorithms in \cref{subsec:lftj-vs-graphWCOJ}.

The other two algorithms are Spark's binary joins: \textit{BroadcastHashJoin} and \textit{SortmergeJoin}.
We compare them against the sequential version of \textsc{LFTJ} and GraphWCOJ in \cref{subsec:spark-vs-lftj}.

We adjust the \texttt{spark.sql.autoBroadcastJoinThreshold} parameter to control
if Spark is using a \textit{BroadcastHashJoin} or a \textit{SortMergeJoin}.

\subsubsection{Datasets}
We run the our experiments on multiple datasets from two different use-cases: social networks and product co-purchase.
We motivate our choice in the next paragraph.
\Cref{table:datasets} includes a list of all graph datasets mentioned throughout the thesis.

\begin{table}[]
    \centering
    \begin{tabular}{llrrl} \toprule
        Name    & Variant              &  Vertices   & Edges          & Source          \\ \midrule
        \textbf{SNB}         & sf1     &             &  453.032       & \cite{snb}      \\
        \textbf{Amazon}      & 0302    & 262,111     &  1,234,877     & \cite{snapnets} \\
                             & 0601    & 403,394     &  3,387,388     & \cite{snapnets} \\
        \textbf{Twitter}     & sc-d    & 81,306      &  1,768,135     & \cite{snapnets} \\
%                             & sc-u    &   TODO      &       TODO     & \cite{snapnets} \\
        \textbf{LiveJournal} &         & 4,847,571   & 68,993,773     & \cite{snapnets} \\
        \textbf{Orkut}       &         & 3,072,441   & 117,185,083    & \cite{snapnets} \\ \bottomrule
    \end{tabular}
    \caption{A summary of all datasets mentioned in the thesis.}
    \label{table:datasets}
\end{table}

The SNB benchmark~\cite{snb} generates data emulating the posts, messages and friendships in a social network.
For our experiments, we only use the friendships relationship (\texttt{person\_knows\_person.csv}) which is an undirected relationship.
Only edges of the kind \textit{src $<$ dst} exist, we generate the opposing edges before loading the dataset, such
that the edge table becomes truly undirected.

The benchmark comes with an extensively parameterizable graph generation engine
which allows us to experiment with sizes as small as 1GB and up to 1TB for big experiments and different levels of selectivity.
The different sizes are called scale-factor or \texttt{sf}, e.g. \texttt{SNB-sf1} refers to a Social network benchmark dataset generated with
default parameters and scale-factor 1.

The Amazon co-purchasing network contains edges between products that have been purchased together and hence are closely related to each other~\cite{snapnets}.
This is a directed relationship from the product purchased first to the product purchased second, both directions of an edge can exist if the order in which
products have been purchased varies.

The Snap dataset collection contains multiple Amazon co-purchase datasets, each of them containing a single day of purchases.
We choose the smallest and biggest dataset from the 2nd of March and the 1st of June 2003 which we call them \texttt{Amazon-0302} and
\texttt{Amazon-0601}.

We pick co-purchase datasets for evaluation because former work often concentrated on social networks and web crawl based
graphs~\cite{myria-detailed,ammar2018distributed} but~\cite{salihoglu2018} points out that the biggest graphs are actually graphs like
the aforementioned Amazon graph containing purchase information.

To allow comparisons with former work, we run a subset of our experiments on the Twitter social circle network from~\cite{snapnets}.
This dataset includes the follower relationship of one thousand Twitter users; each of these follows 10 to 4.964 other users and
relationships between these are included.

The \texttt{LiveJournal} graph represents the friendship relationship of a medium sized social network.

\subsubsection{Graph patterns}

In this section, we detail the graph patterns used throughout our experiments.
Most of the queries are cyclic because that has been shown to be the primary use-case for WCOJ in former research~\cite{olddog,myria-detailed}.
WCOJ's also have been successfully applied to selective path queries in~\cite{olddog,longbin}.

We apply filters to most of our queries to make them more realistic, e.g. a clique query does make more sense if it is combined with a
smaller-than filter, which requires that the attributes are bound such that \textit{a} smaller than \textit{b}, smaller than \textit{c}.
Otherwise, one gets the same clique in all possible orders, which not only takes much more time but is also most
likely not the result a user would want.

We ensure that filters can be pushed down through or in the join by Spark as well as by the WCOJ to compare both algorithms on an equal basis.
A complete list of all queries and filters used is shown in~\cref{table:patterns}.
\Cref{fig:all-queries} shows depiction of all graph patterns.

Patterns and filters are combined as follows.
Cliques and the \texttt{kite} query use smaller than filters which require the bindings to increase
in value according to the variable ordering.
All other queries are run with a filter such that each of their binding must be distinct.

\begin{table}[]
    \centering
    \begin{tabular}{@{}lcccp{6cm}@{}}
        \toprule
        Name     & Parameters                 & Vertices & Edges

        \\ \midrule
        \texttt{triangle} & NA                          & $3$        & 3                 \\
        \texttt{n-clique} & \# vertices                & $n$        & $1/2 \times n \times (n - 1)$ \\
        \texttt{n-cycle}  & \# vertices                & $n$        & $n$                 \\
        \texttt{n-s-path} & \# edges / selectivity  & $n$       & $n - 1$                 \\
    \texttt{kite}  & NA                         & $4$        & $5$                    \\
        \texttt{house}    & NA                         & $5$        & $9$                 \\
        \texttt{diamond}  & NA                         & $4$        & $4$                 \\
        \textbf{Filters}   &                            &          &                   \\
        \texttt{distinct}  &                            &          &                   \\
        \texttt{less-than} &                            &          &                   \\ \bottomrule
    \end{tabular}
    \caption{Summary of patterns and filters used.}
    \label{table:patterns}
\end{table}

\begin{figure}
    \centering
    \subfloat[triangle]{\includesvg[width=0.2\textwidth]{svg/triangle}}
    \subfloat[4-clique]{\includesvg[width=0.2\textwidth]{svg/4clique}}
    \subfloat[5-clique]{\includesvg[width=0.2\textwidth]{svg/5clique}}
    \subfloat[4-cycle]{\includesvg[width=0.2\textwidth]{svg/4cycle}}\\
    \subfloat[5-cycle]{\includesvg[width=0.2\textwidth]{svg/5cycle}}
    \subfloat[diamond]{\includesvg[width=0.2\textwidth]{svg/diamond}}
    \subfloat[kite]{\includesvg[width=0.2\textwidth]{svg/kite}}
    \caption{Queries used in our experiments.}
    \label{fig:all-queries}
\end{figure}

For a selective path query, we first select two sets of nodes with respect to the \textit{selectivity} parameter.
Then we search for all paths of a certain length according to the \textit{edges} parameter, e.g. \texttt{4-0.1-path} finds all
paths between two randomly selected, fixed sets of vertices of length 4.
The sets of nodes contain roughly 10\% of all input nodes and are
not guaranteed to be intersection free.

\subsection{Linear search threshold}\label{subsec:linear-search-threshold}

We run \textsc{LFTJ} and GraphWCOJ with different settings for the \textit{linear search threshold}.
As explained in \cref{subsubsec:leapfrog-triejoin}, we use a binary search to implement the \textit{seek}
method of the \textit{TrieIterators};
it is also used for GraphWCOJ.
It is well known, that a binary search can be optimized by ending it with a linear search on small
search spaces because linear memory access patterns are cheaper than random accesses.
The threshold gives the size of the search space from which to use a linear search instead of
a binary search, e.g. a threshold of 40 means that the algorithm switches to a linear search
once the search space is 40 numbers or less.

We note that \textsc{LFTJ} and GraphWCOJ could behave differently for the same threshold.
This is because Leapfrog Triejoin uses a binary search for both levels of its \textit{TrieIterators},
while GraphWCOJ only uses the binary search for the second levels;
the first level is indexed in a \textsc{CSR}.

In this experiment, we vary the threshold between 1 and 1600 to determine the best value.
These values are chosen such that 1 does not trigger any linear search and that 1600
does not improve the performance anymore (for \textsc{LFTJ}) and triggers no
binary search for GraphWCOJ.
We do so for the 5-clique query on the SNB-1 and on the Twitter dataset.

The results are shown in~\cref{subsec:linear-search-threshold}.
The optimum for LFTJ is around 200 while GraphWCOJ shows the best performance at 1600 and 800 for
SNB-1 respectively Twitter.
This means that GraphWCOJ performs best when there are nearly no binary searches.
A threshold of 1600 triggers no binary search in either of the datasets.

We also note that the effect on the performance of the Leapfrog Triejoin is bigger.

\begin{figure}
    \centering
    \subfloat[SNB-1\label{fig:linear-search-threshold-snb}]{\includesvg[width=0.5\textwidth]{svg/linear-search-threshold-snb}}
    \subfloat[Twitter\label{fig:linear-search-threshold-twitter}]{\includesvg[width=0.5\textwidth]{svg/linear-search-threshold-twitter}}
    \caption{Runtime of \textsc{WCOJs} with different settings for the linear search thresholds.}
    \label{fig:linear-search-threshold}
\end{figure}

We explain the observations as follows: \textsc{LFTJ} does use searches on the first
and second level of the \textit{TrieIterators} while GraphWCOJ uses it only on the second
level.
Hence, the impact is bigger.

The optimal values are different because data of the levels is differently distributed.
The first level lists nearly all vertices while the second level is made of adjacency lists which are more
sparse.
Hence, we assume that the linear searches on the first level are generally longer than
the one on the second level;
note that the threshold only gives an maximum length for linear searches but this is not
necessarily a good indicator for the length of the performed search.

We tried to use different threshold values for the two levels in \textsc{LFTJ}.
We choose the values 200 for the first level and 1600 for the second level because these
are the optimal values according to our experiments.
However, we note that no huge performance gain can be measured.
This is most likely because the runtime is dominated by the searches on the first level.
For simplicity, we do not use two different thresholds for \textsc{LFTJ} in any further experiments.

From this experiment, we conclude that the optimal threshold for \textsc{LFTJ} is 200 and 800
for GraphWCOJ.
We choose 800 for GraphWCOJ because it is on the safe site:
a binary search performance degrades less than the one of a linear search.
We set these values accordingly in the all further experiments.


\subsection{Baseline: \texttt{BroadcastHashJoin} vs \texttt{seq}} \label{subsec:spark-vs-lftj}
% TODO use uniform spelling for broadcasthashjoin
In this experiment, we compare the runtime of our sequential Leapfrog Triejoin implementation with the runtime of Spark's \texttt{BroadcastHashjoin}.
Towards, this goal we ran all queries from~\cref{table:patterns} on our three of our datasets: \texttt{Amazon-0302}, \texttt{Amazon-0601}
and
\texttt{SNB-sf1}.


We show our results in~\cref{fig:spark-vs-lftj}.
\Cref{sssec:seq-analysis} analyzes the results.

Our experiment measures the time it takes to perform a \texttt{count} on the cached dataset using \texttt{BroadcastHashjoin} and
\textsc{LFTJ}.
For \texttt{BroadcastHashjoin}, the time to run the whole query is reported.
For \texttt{seq}, we report setup time and the time, it takes to run the join, separately.
Setup time includes the sorting and materialization.
This section is focused on comparing the runtimes excluding the setup time - rational given in~\cref{sssec:seq-experiment-rational}.

\subsubsection{Experiment Setup}\label{sssec:seq-experiment-rational}
\textbf{Question:} Why do we compare against Spark's \texttt{BroadcastHashjoin} instead of \texttt{SortMergeJoin}? \\
\textbf{Answer:} Because even when all data is arranged in a single partition, for simple sequential processing, Spark
schedules its \texttt{SortMergeJoin} to use a shuffle.
A shuffle writes and reads data to and from disk.
Hence, \texttt{SortMergeJoin} is much slower than a \texttt{BroadcastHashJoin}.
We compared the algorithms on the \texttt{Amazon-0601} dataset for the \texttt{triangle} (8.1 seconds vs 58.9 seconds) and
\texttt{5-clique} pattern (32.9 seconds vs 850.9 seconds).
We assume that Spark is able to optimize its broadcasts when \texttt{local[1]} is used to start the Spark session because then Spark uses the driver as executor.

\textbf{Question:} Why do we exclude setup times from the WCOJ times?\\
\textbf{Answer:} Because system is meant to cache the readily sorted and formatted as \textsc{CSR}'s and reuse it for multiple queries.
We anticipate that this is necessary to benefit from \textsc{WCOJ}'s in general.

%\textbf{Question:} Why is the time to copy results into \texttt{UnsafeInternalRow} format for WCOJ counted as setup time?\\
%\textbf{Answer:} It is time solely spent for integration with Spark and not Leapfrog Triejoin specific.
%Furthermore, it could be avoided by working directly on the \texttt{UnsafeInternalRow} format within our \texttt{seq} implementation.
%However, this would require us to work with unmanaged memory (the \texttt{UnsafeInternalRow} interface is slower than working on \texttt{Arrays})
%and we deem this as an unnecessary engineering overhead.

\textbf{Question:} Is Spark's code generation a huge advantage for the \texttt{BroadcastHashjoin}?\\
\textbf{Answer:} Yes, we ran Spark without code generation for comparision on the \texttt{Amazon-0302} dataset for the \texttt{triangle}
query and \texttt{5-clique}: with code generation Spark takes 3.1 and 4.2 seconds without 14 and 16 seconds.

\subsubsection{Analysis}\label{sssec:seq-analysis}

We are able to beat Spark's \texttt{BroadcastHashjoin} on all datasets and queries except \texttt{5-clique-lt} on \texttt{Amazon-0602}.
Generally, we see that for \texttt{n-clique} patterns the speedup over Spark decreases for bigger $n$.
This is due to the fact that many binary joins in a \texttt{n-clique} are actually semi-joins which to do not increase but decrease the size of intermediary results,
e.g. for \texttt{5-clique} on \texttt{Amazon-0302} only 3 out of 9 joins lead to a bigger intermediary result.

The cycle query results are highly interesting because we see an increasing speedup for higher $n$ on \texttt{Amazon-0602} but a
decreasing speedup on \texttt{Amazon-0302}.
% TODO n-cycle results for snb

The \texttt{House} and \texttt{5-clique} pattern seem to be quite similiar - the \texttt{House} is a \texttt{5-clique} with two missing
edges.
However, as the count of their results indicates these two edges lead to dramatically different outcomes.
Hence, their different timing and speedup behaviour.

The \texttt{Kite} pattern produces consistently the second highest speedup after the \texttt{3-clique}.
Most likely due to the fact that a \texttt{Kite} is two triangles back-to-back.

The path query shows very different behaviour on the \texttt{Amazon} and the \texttt{SNB} datasets.
This might be due to the different selectivity; it is extremely high on the co-purchase datasets and rather low on the social network
benchmark.
This different in selectivity is not surprising given that the \texttt{SNB} network fulfills the small world property, while the
\texttt{Amazon} dataset relates products purchased together which naturally leads to multiple loosely connected, denser components.

% TODO maybe run path query with different selectivity

Finally, we observe that all three datasets lead to quite different results which are most likely not comparable to each other without deeper research
in the characteristics of the datasets themselves.

In particular, it becomes clear that co-purchase datasets and social network datasets must have very different characteristics.
Although, \texttt{SNB-sf1} is much smaller than \texttt{Amazon-0601}, queries on it take a similar or even much more time,
e.g. \texttt{5-clique} takes 14.21 seconds on the bigger dataset and 12.65 seconds smaller, even though, the result set is much
smaller on \texttt{SNB-sf1};
\texttt{4-cycles} takes roughly 8 times longer on the small dataset and has a much bigger result set.
In general, we see a higher speedup on \texttt{SNB-sf1}

\begin{figure}
    \centering
    \subfloat[Amazon0302]{
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-amazon}
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-amazon-long}
    }\\
    \subfloat[Amazon0601]{
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-amazon0601}
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-amazon0601-long}
    }\\
    \subfloat[SNB-sf-1]{
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-snb}
        \includesvg[width=0.5\textwidth]{svg/spark-wcoj-snb-long}
    }
    \caption{Runtime of a Leapfrog Triejoin and Spark's \texttt{BroadcastHashJoin}}
    \label{fig:spark-vs-lftj}
\end{figure}


%\begin{table}
%    \centering
%
%    \input{generated/seq-table-ama0302}
%    \vspace{0.3cm}
%
%    \input{generated/seq-table-ama0601}
%
%    \vspace{0.3cm}
%    \input{generated/seq-table-snb-sf1}
%    \caption{Runtimes for \texttt{BroadcastHashJoin} and \texttt{seq}.
%    The speedup is calculated between join times and excludes setup.
%    From top to bottom for dataset: \texttt{ama-0302}, \texttt{ama-0601} and \texttt{snb-sf1}.
%    All times in seconds.
%    }
%    \label{table:seq-vs-bhj}
%    % TODO align and remove headers
%\end{table}

\subsection{\textsc{LFTJ} vs GraphWCOJ} \label{subsec:lftj-vs-graphWCOJ}

In this experiment, we compare sequentials runs of the Leapfrog Triejoin and GraphWCOJ
on the \texttt{Amazon}, \texttt{SNB-1} and \texttt{Twitter} datasets.
We do not show the run-time of \texttt{Path} queries because GraphWCOJ is not able to run
them\footnote{\texttt{Path} queries require us to filter the input relationship before
the join. This has not been implemented for GraphWCOJ due to time constraints.}.

We show the run-time of the queries on  the different datasets in~\cref{fig:lftj-graphWCOJ}.
We present the performance of the Leapfrog Triejoin, GraphWCOJ and GraphWCOJ without the
materialization optimization.

{\itshape Comment for Peter and Bogdan:
  The materialization showed to be not as good of an optimization as I thought;
  in some cases it turns out to be slower.
  This has two reasons:

  I found that it is faster to build the intersection my way because it causes less seek
  calls to the underlying iterators due to the fact that I start the intersection with the
  smallest list.
  So it does not improve computation because of better caching behaviour as I used to believe.

  Then I experimented with the linear search thresholds and found that the algoritm gets faster
  when I use a higher threshold.
  Now, there are nearly no binary searches.
  Hence, the original algorithm got faster and the overhead that used to be avoided by my
  optimizations (binary searches) is gone.
  Therefore, the optimizations doesn't look great anymore.

  So far I'm not sure what to do about it and present the results as they are.
  In many cases, it's slightly faster, in some slower.
  In general, it is not a huge improvement anymore.
}



\begin{figure}
    \subfloat[Amazon-0302]{\includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-amazon}}
    \subfloat[Amazon-0601]{
      \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-amazon0601}
      \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-amazon0601-long}
    }\\
    \subfloat[SNB-1]{
    \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-snb}
    \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-snb-long}
    }\\
    \subfloat[Twitter]{
    \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-twitter}
%    \includesvg[width=0.3\textwidth]{svg/lftj-graphWCOJ-twitter-long}
    }
    \caption{
      WCOJ run time of \textsc{LFTJ} and GraphWCOJ on different datasets and queries.
      Diamond, house and cycle queries are not reported for Twitter because of their high
      run-time of over an hour.
    }
    \label{fig:lftj-graphWCOJ}
\end{figure}

\paragraph{Observations}

We first compare the Leapfrog Join algorithm with the GraphWCOJ without the materialization optimization.

Throughout all datasets, we see that GraphWCOJ is faster than a \textsc{LFTJ} for all queries.
The biggest speedups are reached for 5-cliques and the lowest speedup for 4-cycles.
The maximum speedup over all queries and datasets is 11.4 for a 5-clique query on \texttt{Amazon-0601}.
The lowest speedup is 1.2 on a 4-cycle query on \texttt{SNB-sf-1}.
Generally, the performance gain from using GraphWCOJ is higher for bigger and denser queries like clique
queries.

The \texttt{Amazon} datasets show quite similar behaviour over all queries.
\texttt{SNB-sf-1} and \texttt{Twitter} queries do not profit from using GraphWCOJ as much as
the \texttt{Amazon} datasets.

The influence of the materialization optimization (described in~\cref{subsec:graphWCOJ-materalization})
is mixed;
some queries can benefit, others cannot.

In general, queries that see the highest speedup from using GraphWCOJ, also benefit most strongly
from materialization of the intersections, i.e. clique queries.
4-cycles, diamonds and kites are sometimes slower when we materialize the intersections.

The \texttt{Amazon-0302} dataset is the only dataset that shows increased performance for all
queries.

\texttt{Amazon-0601} does not profit from materialization;
the query run-time does not change for the clique queries and house query and
increases for kite, diamond and 4-cycle.

On the other two datasets, we see improvements for the clique and house query but decreased
performance on diamond and cycle.


% TODO observation denser queries profit more
% TODO SNB-sf-10 to rule out dataset size for improvement
% TODO why do 4-cycle and diamond become slower.


\subsection{Scaling of \textit{Graph\textsc{WCOJ}}} \label{subsec:scaling-graphWCOJ}

In this section, we aim to analyse and compare the scaling of Graph\textsc{WCOJ} using different
partitioning schemes.
Towards this goal, we run Graph\textsc{WCOJ} on datasets of different size namely \texttt{Twitter},
\texttt{LiveJournal} and \texttt{Orkut}.
We compare two partitioning schemes: Shares and work-stealing.
These are the two most promising schemed identified in \cref{sec:worst-case-optimal-join-parallelization}.
The experiment is performed on 3-clique, 4-clique and 5-clique.
3-clique is the smallest of our queries.
Therefore, it is most difficult to scale.
4-clique and 5-clique take much longer than 3-clique.
Hence, it shows how query size influences the scaling.
Also, it increases the job size for the \textit{work-stealing} partitioning scheme.

% TODO paragraph about section structure

\subsubsection{Results}

\begin{figure}
    \centering
    \subfloat[Twitter dataset\label{fig:graphWCOJ-scaling-twitter}]
      {\includesvg[width=0.5\textwidth]{svg/graphWCOJ-scaling-twitter}}
    \subfloat[LiveJournal dataset\label{fig:graphWCOJ-scaling-livej}]
      {\includesvg[width=0.5\textwidth]{svg/graphWCOJ-scaling-livej}}
    \newline
    \subfloat[Orkut dataset\label{fig:graphWCOJ-scaling-orkut}]
      {\includesvg[width=0.5\textwidth]{svg/graphWCOJ-scaling-orkut}}
    \subfloat[Twitter 3-clique join run-time only \label{fig:twitter-3-clique-scaling}]
    {\includesvg[width=0.5\textwidth]{svg/twitter-3-clique-scaling}}
    \caption{Scaling behaviour of Shares and work-stealing on three different datasets
      and two different queries.
      The batch size parameter for \textit{work-stealing} is chosen for balance between lock contention and worker skew:
      50 for Twitter and 3-clique on LiveJournal, 1 for 5-clique on LiveJournal and 20 on the Orkut dataset.
    }
    \label{fig:graphWCOJ-scaling}
\end{figure}

We first describe our expectations of the experiment outcome.
We assume that scaling improves with the dataset size.
Hence, we should see the highest speedups for Orkut, then LiveJournal and the lowest speedups for Twitter.
Also, we expect the scaling to improve with the query size.
Both hypothesis are grounded in the fact that more work to distribute often leads to stronger scaling.
Additionally, we believe that \textit{work-stealing} shows better scaling than Shares because it does not duplicate work.
Finally, we have no clear cut expectations to the scaling behaviour of \textit{work-stealing}.
Theoretically, we could expect linear scaling for it because no work is duplicated, synchronization overhead is minimal and
work balance should be given by the scheme.
However, we measure on a quite complex hardware platform which complicates scaling behaviour.

First of all, we work on a machine with 4 sockets.
This can influence scaling positively and negatively.
Positively because adding more sockets means to add significantly more L3 cache (30 MB shared per socket).
If we do not use all cores on a socket, each used core can use a bigger share of this cache.
Negatively because each socket is in a different NUMA zone and the graph is not guarantued to be chached in all
NUMA zone.
Indeed, Spark shares the broadcasts for all tasks on a single executor.
So there is only one copy in memory.

Additionally, we run on an Intel processor with hyperthreading.
Hence, we can not expect linear speedup above 48 workers because after multiple threads will share resources and cannot be
expected to reach the same performance as two cores.

To conclude, we expect sub-linear speedup for Shares and better but still sub-linear speedup for \textit{work-stealing}.
Anyhow, super-linear scaling in MapReduce like systems is not unheard of and could be possible on our machines.
% TODO cite the internet source from Monday.

We describe our observations per dataset;
starting with Twitter.
As expected, both partitioning schemes scale better when we increase the query size.
For 5-clique, \textit{work-stealing} exhibits near linear scaling up to 48 workers, while
clique-3 reaches the maximum speedup of 6.22 for 8 workers.
The highest speedup for 5-clique is 45 on 96 workers; clique-3 reaches its highest speedup
with 13.2 on 64 workers.
Shares lacks behind in scaling for both queries and all levels of parallelism.
The best observed speedup is 21.3 for 5-clique and 96 workers.

We note that the 3-clique query does not scale well because there is not enough work.
Therefore, the run-time is dominated by overheads, e.g. the time it takes until Spark starts
the first job and the time it takes to finalize the query by Spark.
The overhead calculated by $(queryEnd - queryStart) - (lastTaskCompleted - firstTaskScheduled)$ is
roughly 0.13 seconds for all levels of parallelism and the whole query runs for 0.19 seconds on
48 cores.
We depict the speedup archieved when we measure only the time spent with the join in \cref{fig:twitter-3-clique-scaling}.

% TODO bad scaling for hyperthreading

The experiment on LiveJournal confirms our hypothesis that bigger datasets lead to better
speedups;
the highest observed speedup is 61.2 for \textit{work-stealing} on 3-clique and
36.81 for Shares on 5-clique each with 96 workers.
Also, we can confirm that Shares scales better on 5-clique than on 3-clique; with the exception of 32 workers.
However, this is not the case for \textit{work-stealing}.
\textit{work-stealing} shows better speedups on clique-3 than on clique-5.
Nevertheless, \textit{work-stealing} beats Shares on both queries and all levels of parallelism.
% TODO analyse, higher skew rigth, at least name reason, is skew higher because of 0th vertice?
% TODO effect of dataset size leads to 5-clique scaling the same or worse

Additionally, we see three unexpected scaling behaviours for LiveJournal.
First, super-linear scaling for 3-clique and \textit{work-stealing}.
We hypnotize that this is the fact because if the 32 processes are distributed over all 4 sockets they share in total
120 MB of L3 cache while a single process can use only 30 MB of L3 cache.
%To confirm this we rerun the experiment with 1, 8, 16 and 32 workers while using \textit{taskset} to bind the application
%to the first 8, 16 or 32 cores.
%This rules out the use of more than 1, 2 or 3 sockets respectively.
%In this experiment, we measure speedup of 8.6, 16.6 and 32.9 for 8, 16 and 32 workers.
%This is significantly lower than the speedup measurements without \textit{taskset}.
%We conclude that this confirms our hypothesis and believe that the slight super-linear
%scaling that remains arises from the bigger amount of L1 and L2 cache in the system.
% TODO run with perf counter
% TODO note why do we have locallity in data accesses?

Second, the scaling of 4- and 5-clique is worse than for 3-clique.
Our explanation is that 4- and 5-clique show skew even with \textit{work-stealing}.
% TODO skew relationship
%
% TODO datasets in ttt or not?
This is because \textit{work-stealing} partitions work along the first variable binding.
Hence, the size of a single job in \textit{work-stealing} is never smaller than the work of finding all bindings for a single
first binding.
That means a single long-running job towards the end of the \textit{work-stealing} queue can
result in a single task running longer than the others which delays the whole query.

We measure the time at which a task finishes.
We define skew for \textit{work-stealing} as the time between the average worker finishes and
the time of the last worker to finish.
In \cref{table:skew-liveJ} and \cref{table:skew-orkut} we show the total skew and the percentage of
skew in the whole query time for the LiveJournal respectively the Orkut dataset.

We note that the residual skew correlates with the scaling behaviour;
the higher the percentage of skew in the whole query time the worse the query scales.

The total skew grows with the level of parallelism.
We explain this as follows.
Lets assume there is at least one job which takes significantly longer than most of the jobs in
the work-stealing queue.
This job is picked by a worker.
When more executors are added which work on the remaining jobs, the likelyhood of this one big
job adding significant skew raises because the other jobs are finished faster.

This experiment shows that the job size is not fine-grained enough for bigger queries and a high level of parallelism.
We see that the skew can raise up to nearly half of the total run-time for the 5-clique query
on Orkut.
We address this issue in~\cref{subsubsec:finer-grained-work-stealing}.
However, we want to point out that the skew raises significantly as soon as we use more cores
than physical cores available.
This could hint that part of the problem is causes by hyper-threading.
We do not investigate this issue further.

\begin{table}
    \centering
    \input{generated/skew-liveJ.tex}
    \caption{
    Total skew in seconds and percentage of skew in the total query time displayed for different
    queries and levels of parallelism on the LiveJournal dataset.
    }\label{table:skew-liveJ}
\end{table}


\begin{table}
    \centering
    \input{generated/skew-orkut.tex}
    \caption{
    Total skew in seconds and percentage of skew in the total query time displayed for different
    queries and levels of parallelism on the Orkut dataset.
    }\label{table:skew-orkut}
\end{table}

Fourth, Shares exhibits lower speedup of 12.1 for 64 workers which is
lower than for 32 workers (14.7) and 14.8 for 96 workers.
This can be explained by the chosen Shares configuration.
For 32 workers, the best configuration is given by the hypercube of the sizes 4, 4, 2.
For 64 workers, we get the hypercube with 4 workers on each axis.
Hence, although we are doubling the number of workers, we use the new workers only to partition
work along the last axis, in the case of 3-clique along the C attribute axis.
Partitioning work along the last axis leads to a high amount of duplicated work on the first
two axis.
Additionally, with 64 workers at least 12 of these workers are not exclusive cores but cores shared by
two hyperthreads.
In total, we get a lower speedup.
This changes slightly for 96 workers because the optimal hypercube configuration here is 6, 4, 4 which
adds more workers along the first axis.
However, the scaling only increases marginally by 0.1 from 32 workers which is quite disappointing given
that the number of threads increased by a threefold.

One could argue that we should use a different definition of \textit{best} hypercube configuration.
As we see, it is not necessarily efficient to distribute the computation along the last axis.
% TODO prefix shares
%We implemented version of the configuration finder that considers only the first \textit{i} axes and
%call this partitioning scheme \textit{i-prefixShares}.
%However for time constraints, we do not investigate this issue further and do not include \textit{i-prefixShares}
%in our further experiments.

The Orkut and LiveJournal datasets lead to highly similar scaling results:
super-linear scaling for \textit{work-stealing} up to 48 workers,
\textit{work-stealing} scales significantly better than Shares.
Shares exhibits less speedup for 64 workers than for 32 and 64 workers.



% TODO experiment about scaling of Spark

\subsection{Distributed work-stealing}

% TODO take out reference to spark local mode only from background and abstract.

% TODO 5-clique query
We run the distributed version of work-stealing as described in~\cref{subsubsec:distribute-work-stealing}
on the LiveJournal and Orkut dataset for the 3-clique query.

For this experiment, we use four machines as described in~\cref{subsec:setup}.
Each of this machine has 48 physical cores with hyper-threading.
In total, the Spark cluster has 192 physical cores and 384 virtual cores.
We run the experiments on 16 to 192 of these cores.
The tasks are evenly distributed over all four machines for all levels of parallelism by
the standard behaviour of Spark's standalone mode scheduler.



% comparision against other work
%   Dewitt
%   Andreas Amler
%   Old dog
%   LFTJ
%   Richard