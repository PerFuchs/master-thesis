\section{Implementation}\label{sec:implementation}

\subsection{General sequential version (\textit{seq})}\label{subsec:general-sequential-version}
We implement the Leapfrog Triejoin~\cite{leapfrog} as our general sequential version of a WCOJ.
However, instead of using B-Trees as a backing data structure, we use sorted arrays and a binary search
to for its backing, which has been described in~\cite{myria-detailed} and is called Tributary join in their paper.
Our Leapfrog Triejoin is implemented in three components, which we explain in this order below: \textit{LeapfrogJoin}, \textit{ArrayTrieIterable} and
\textit{LeapfrogTriejoin}.

The Leapfrog join is a variant of the sort-merge join for unary relationships, original described in~\cite{leapfrog1,leapfrog2}. % TODO see LFTJ paper 4 and 7
To join $k$ unary relations $A_1(x)$, $A_2(x)$, \dots, $A_k(x)$ it takes one iterator per input relations and offers an iterator
interface that yields the intersection of all relations.
It requires that it's input iterators offer a \textit{key} method in $\mathcal{O}(1)$, a \textit{next} method and
a \textit{least\_upper\_bound(key: Int)} both in $\mathcal{O} (\log n)$ ($n$ defined as the size of the input relationship).
\textit{least\_upper\_bound} moves the iterator to the first position of the sought \textit{key} or the first position of the
next higher value.
An idiotmatic implementation of a Leapfrog join is shown in~\cref{lst:leapfrog-join}, for the optimized implementation see
\texttt{leapfrogTriejoin.LeapfrogJoin} in our repository.  % CODEREF

\begin{listing}[H]
    \inputminted{scala}{code/LeapfrogJoin.scala}
    \caption{Leapfrog join.}
    \label{lst:leapfrog-join}
\end{listing}

To support j-arity relations, $A(a_1, a_2, \dots, a_j)$ we add two methods to the iterator interface that represents the input
relationships: \textit{up} and \textit{down} both are required to work in $\mathcal{O} \log n$.
We call this new iterator \textit{Trieiteraor} because it represents the relationship as a trie, see~\cref{fig:trie-example}.

% TODO Trieiterator not in textit
The implementation of a \textit{Trieiterator} backed by a columnwise representation of the relation using one array
per column is straight forward, we outline the basic ideas next and refer to the interested reader to
\texttt{leapfrogTriejoin.ArrayTrieIterable.TrieIteratorImpl} in our repository for further details.  % CODEREF
It helps to think about the \textit{Trieiterator} as consisting out of a linear component, containing the functions
\textit{key}, \textit{next} and \textit{seek}, and horizontal component, made off the functions \textit{up} and \textit{down},
to move the linear component from one trie level to another.
First, we explain the horizontal component.
They keep track of the current \textit{level} of the \textit{Trieiterator} and the \textit{startPosition} and \textit{endPosition}
for in the columns,
e.g. in~\cref{fig:trie-example} when the current \textit{level} is 1 (or x) and the key equals 4 the \textit{startPosition} is 2 and
the \textit{endPosition} is 5 because the value 4 occurs 3 times.
With these bookkeeping variables, updated by \textit{up} and \textit{down}, one can implement the linear part by
a binary search over the current column (given by \textit{level}) which is limited to \textit{startPosition} and \textit{endPosition}.

\begin{figure}
    \centering
    \includesvg[height=5cm]{trie}
    \caption{A 3-ary relationship as table (left) and trie (right), to position the iterator at the tuple (1, 1, 5) one
    calls \textit{down} twice, \textit{key} returns now 5, after a call to \textit{next}, \textit{key} returns 6 and \textit{up}
    would lead to \textit{key} returning 1.}
    \label{fig:trie-example}
\end{figure}

The Leapfrog Triejoin combines \textit{Trieiterators} and Leapfrog joins to join $k$ relationships of arbitrary arity.
Its input is one \textit{Trieiterator} per relationship, from this it builds one Leapfrog join per attribute which
receives references to all \textit{Trieiterators} of relationships containing this attribute, e.g. for the triangle query
\textit{R(a, b), S(b, c), T(a, c)} the Leapfrog Triejoin receives three Trieiterators, for \textit{R}, \textit{S} and \textit{T},
and builds three Leapfrog joins, for $a$, $b$, $c$, which receive references to two TrieIterators each.
To generate the join result the Leapfrog Triejoin operates the horizontal components of the Trieiterators directly and
uses the Leapfrog joins to operate the linear component.

% TODO can I reference lines?
We show an idiomatic implementation in~\cref{lst:leapfrog-triejoin}, a performance oriented implementation can be found in our
repository in \texttt{leapfrogTriejoin.LeapfrogTriejoin}.
The listings contains two important functions: the initialization function from line TODO to line TODO % LINE
and the \textit{moveToNextTuple} function at line TODO. % LINE
We go through these functions in order.
The initializer gets two arguments: a mapping from variables to \textit{TrieIterators} (each \textit{TrieIterator} belongs to
the list of attributes of its relationship) and the global variable ordering as a list of \textit{Strings}.
First, it creates one \textit{LeapfrogJoin} per variable (line 2 to 9) which receives references % LINE
to each \textit{TrieIterator} operating on a relationship with this attribute; and builds a mapping from variables to
all \textit{TrieIterators} acting on a relationship with an attribute of the same name (line TOOD). % LINE
Then we initialize \textit{depth}, \textit{bindings} and \textit{atEnd} (line TODO to line TODO). % LINES
\textit{depth} and \textit{bindings} are an internal variable storing the index of the variable to bind currently and the
current bindings for all variables up to \textit{depth}.
\textit{atEnd} signals that the join has been completed to the client.
In line TODO, we move the join to the first tuple if it is not empty (line TODOff). % LINE
That means to move all \textit{TrieIterators} to their deepest level and storing the current binding for each level
in \textit{bindings}, so that these bindings are returned on the first call to \textit{next} - the join stores one output
tuples in bindings and returns it in \textit{next} after moving to the next tuple. % TODO change this in the implementation.

\textit{moveToNextTuple} implements a depth-first traversal of the intersection of the \textit{TrieIterators}.
This traversal needs to stop each time when a complete tuple has been found to support the iterator interface of the join.
Therefore, it is implemented as a state-machine which stops each time the deepest level is reached and all variables bound
(loop condition in line TODO). % LINE
The next action of the state machine is determined by the outcome of the current action variable.
Hence, we can characterize the state machine by describing each possible action and it's possible outcomes.
There are three possible actions: \textit{NEXT}, \textit{DOWN}, \textit{UP}.
We summarize the possible actions, conditions for the next action and
if the mainloop of the state machine yields the next tuple in~\cref{table:lftj-state-machine} and describe each action below.

First, \textit{NEXT} moves the \textit{LeapfrogJoin} at the current depth to the next possible binding for its variable (line TODO). % LINE
Then if \textit{LeapfrogJoin} reached its end, we continue with the \textit{UP} action (line TODO), % LINE
otherwise we set the binding and continue by the \textit{NEXT} action, if we are at the deepest level or by moving
to the next deeper level by the \textit{down} action (line TODO). % LINE
Second, \textit{DOWN} moves to the next variable in the global variable ordering by opening all related \textit{TrieIterators}
(line TODO) % LINE
A \textit{DOWN} can be followed by an \textit{UP} if the \textit{LeapfrogJoin} is \textit{atEnd} (line TODO),
by a \textit{NEXT} action if the trie join is at its lowest level (line TODO), or
by another \textit{DOWN} to reach the last level.
Finally, \textit{UP} can signal the completion of the join if all bindings for the first variable in the global ordering have
been explored, or in other words, the first \textit{LeapfrogJoin} is \textit{atEnd} (condition \textit{depth == 0 $\wedge$ action ==  UP\_ACTION} line TODO). % LINE
Otherwise, all \textit{TrieIterators} corresponding to the current variable are moved upwards
and \textit{depth} and \textit{bindings} updatd (lines TODO, TODO and TODO).  % LINE
Then, this action is followed by another \textit{UP} or a \textit{NEXT} depending on \textit{atEnd} of the current \textit{LeapfrogJoin} (lines TODO). % LINE
label \ref{myline}

\begin{table}[]
    \centering
    \begin{tabular}{@{}llll@{}}
        \toprule
        Action                & Condition                                  & Next action & Yields \\ \midrule
        \multirow{3}{*}{NEXT} & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd $\wedge$ reachedMaxDepth             & NEXT        & yes    \\
        & !lf.atEnd $\wedge$ !reachedMaxDepth            & DOWN        & no     \\
        & & &\\
        \multirow{3}{*}{DOWN} & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd $\wedge$ reachedMaxDepth             & NEXT        & yes    \\
        & !lf.atEnd $\wedge$ !reachedMaxDepth            & DOWN        & no     \\
        & & &\\
        \multirow{3}{*}{UP}     & depth == 0, means highest lf.atEnd is true & NA          & yes    \\
        & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd                                  & NEXT        & no     \\ \bottomrule
    \end{tabular}
    \caption{Summarizes which actions follow from the current action under certain conditions. \textit{lf} abbreviates the
    \textit{LeapfrogJoin} of the current variable.
    \textit{reachedMaxDepth} is true if we currently find bindings for the
    last variable in the global order.
    The columns \textit{Yields} details if the main loop of the state machine yields before computing the next action,
    this is the case, when \textit{bindings} contains a complete tuple.
    }
    \label{table:lftj-state-machine}
\end{table}
% TODO use the word open not down for the trieiterator

\begin{listing}[H]
    \inputminted[mathescape, linenos=true]{scala}{code/LeapfrogTriejoinIdiomatic.scala}
    \caption{Shows the main methods of \textit{LeapfrogTriejoin}, the initializer and \textit{moveToNextTuple} functionality
    helper methods are detailed in~\cref{lst:leapfrog-triejoin-helpers}.}
    \label{lst:leapfrog-triejoin}
\end{listing}

\begin{listing}[H]
    \inputminted{scala}{code/LeapfrogTriejoinHelpers.scala}
    \caption{\textit{LeapfrogTriejoin} helpers.}
    \label{lst:leapfrog-triejoin-helpers}
\end{listing}

\subsubsection{Optimizations}
A simple, idiomatic Scala implementation of the Tributary join is not able to beat Spark's \textit{BroadcastHashjoin} on any other query than the triangle query.
Hence, we spent roughly 2 weeks to optimize our first implementation.
After, we are able to beat Spark's \textit{BroadcastHashjoin} on nearly all queries and datasets.
In this section, we discuss the implemented optimization and give a rough estimate how important each of these are.
In total, we improved the WCOJ running time from 248.2 seconds to 44.5 seconds on the unfiltered 5-clique query on the
\textit{Amazon-0602} dataset.
We list all optimizations in~\cref{table:optimizations-seq} and label them `very important', `important' and `minor' based on the performance improvement directly after applying it.
It is not helpful to give more detailed information on the effect of single optimization because they are not independ of each other.
Hence, they might have a hugely different effect when applied in different order, e.g. we first applied a optimization to the binary search of the arrays and then
optimized the \textit{LeapfrogJoin.next} method to avoid many of its searches, giving detailed runtime measurements for the binary search optimization would
overestimate its value.
It is out of scope of this work to study the dependency and ordering of the optimization to gain correct runtime measurements.

We discuss the optimization in categories in this order: Leapfrog Triejoin specific, binary search specific, Spark related, Scala related and general.
We conclude the section with one paragraph of optimizations that do not improve performance.
Binary search specific optimizations become a category on its own because the sorted search is the most expensive operation in the Tributary join.
According to profiler sessions the join spents more than 70\% of its time in this method. % TODO exact time
This result is in line with the observation that `in the Tributary join algorithm, the most expensive step is the binary search' from~\cite{myria-detailed}.

\begin{table}[]
    \begin{tabular}{@{}lp{12cm}l@{}}
        \toprule
        Category                       & Optimization                                                                           & Impact         \\ \midrule
        \multirow{2}{*}{\textbf{LFTJ}} & \textit{LeapfrogJoin.init} avoid sorting iterators                                               & very important \\
                                       & \textit{ArrayTrieIterable.next} in $\mathcal{O} (1)$ for deepest level                               & very important \\
        \hline
        \multirow{2}{*}{\textbf{Binary search}} & linear search for short search spaces                                                  & important      \\
                                       & avoiding unnecessary conditions                                                        & important      \\
        \hline
        \textbf{Spark}                  & direct use of arrays instead of ColumnVector                                           & important      \\
        \hline
        \multirow{4}{*}{\textbf{Scala}}         & use \textit{while} instead of \textit{map}, \textit{foreach}, \textit{exists}, etc     & very important \\
                                       & use \textit{Array} instead of Scala's collections                                      & very important \\
                                       & use of \textit{private{[}this{]}}                                                      & minor          \\
                                       & enable compiler optimization                                                           & minor          \\
        \hline
        \multirow{3}{*}{\textbf{General}}& remove array lookups from the critical path \textit{column(depth)(position) $\rightarrow$ currentColumn(position)} & very important \\
                                       & use \textit{Array} instead of \textit{Map} if keys are integers and dense              & important      \\

                                       & strength reduction \textit{(i + 1) \% 5} $\rightarrow$ \textit{if (i == 4) 0 else i+ 1}         & important      \\ \bottomrule

    \end{tabular}
\caption{Summary of all optimizations used for \textit{seq} and an estimate of their impact. }
\label{table:optimizations-seq}
\end{table}

We applied to Tributary join specific optimizations one in the class \texttt{leapfrogTriejoin.LeapfrogJoin} (see also~\cref{lst:leapfrog-join}) and one
in the \texttt{leapfrogTriejoin.ArrayTrieIterable.TrieIteratorImpl}.
The \textit{LeapfrogJoin.init} method can be improved by avoiding to sort the \textit{TrieIterators} (line TODO)  % LINE
- the unoptimized implementation is described as such in the original Leapfrog Triejoin paper~\cite{leapfrog}.
However, we can start moving the \textit{TrieIterator} without sorting them and have them sorted in $\mathcal{O} \log n$ with $n$ the numbers of iterators.
This improves over sorting in two ways: (1) it starts moving the \textit{TrieIterators} to their next intersection immediately without sorting them first and
(2) it arrives at a sorted order in less steps than sorting.
For that we find the maximum \textit{key} value in all iterators and store the index of this \textit{TrieIterator} in \textit{p}.
Then we move the \textit{TrieIterator} at $p + 1$ to the least upper bound of this value (by calling \textit{seek}) and store the result as the new maximum.
We proceed with this process, with wrapping \textit{p} around when it reaches \textit{iterators.length}, until \textit{p} equals the original maximum index.
Now, we are either in a state in which all \textit{TrieIterators} point to the same value and we are done - the \textit{LeapfrogJoin} is initialized -
or we arrived at a state in which the array \textit{iterators} is sorted according to \textit{key} and can proceed as in the original \textit{LeapfrogJoin}.
To apply this optimization one replaces the call to \textit{sort} in line TODO with the procedure explained above~\footnote{The implementation of Scala's array sort for objects is really
slow because it copies the array twice and casts them to \textit{Java.object} to use Java's sorting methods. Before we applied the sorting optimization above, we replaced Scala's sort
method with an optimized insertion sort, which was way faster than Scala's sorting method - the \textit{iterator} array contains normally at most 20 items.}.

Then, we can optimize the \texttt{ArrayTrieIterble.TrieIteratorImpl.next} method.
This method moves the to the next value on the same level of the trie.
Hence, it generally runs in $\mathcal{O} (\log n)$ with $n$ the number of tuples in the relationship because it needs to find the least upper bound of \textit{key + 1}.
However, under the assumption that all tuples are unique - which is fulfilled for the use-case of an edge relationship for graphs - the last level of the trie
is unique.
Hence, we can move to the next value by simply increasing the position by one, which is an operation in $\mathcal{O} (1)$.

The binary search is the most expensive operation of the Leapfrog Triejoin.
Hence, special attention needs to be paid while implementing it.
Our most important optimization is to change to a linear search once we narrowed the search space a certain threshold - currently at 60 values.
We experimented with values from 0 to 400 and found that 60 was optimal but even going as high as 120 values would not change the performance much.

Another important optimization is to avoid unnecessary if-statements in the loop of the binary search, e.g. the implementation of Wikipedia and many other
example implementation use an if-statement with three branches for smaller, bigger and equal but two branches for greater than and less-or-equal suffice for a least upper bound search.
A similar optimization can be applied to a linear search on a limited space of a sorted array: intuitively one would use the while-loop condition \textit{array(i) > key $\wedge$ i < end} with
\textit{key} being the key to find the least upper bound for, \textit{i} the loop invariant and \textit{end} the exclusive end of the search space.
Anyhow, it is faster to check for \textit{key > vector(end - 1)} once before the loop and return if this is the case because the value cannot be found in the search space.
This obviously circumvents the main loop of the linear search;
additionally, it simplifies the loop condition to \textit{array(i) > key}.

The Spark infrastructure uses the interface \texttt{ColumnVector} to represent columns of relationship.
The implementation \texttt{OnHeapColumnVector} is a simple wrapper around an array of the correct type with support for \textit{null} values and \textit{append} operations.
First, we used this datastructure to represent our columns but we could see a clear increase in performance by replacing it by an implementation that exposes the array
to allow the binary search to run on the array directly.
This is likely due to saving virtual function calls in the hottest part of our code.
The implementation is straightforward and can be found in our repository in \texttt{leapfrogTriejoin.ExposedArrayColumnVector}; we implemented it only for the \texttt{Long} datatype.

We found many standard optimizations and Scala specific optimizations to be really useful.
Most likely these are the optimizations that brought the biggest performance improvements.
However, they are well-known, so we mention them only in the~\cref{table:seq-optimizations}.
For Scala specific optimizations one can find good explanations at~\cite{databricks-scala-guide}.

Apart from the aforementioned very useful optimizations, we investigated multiple other avenues in hope for performance improvements which do not succeed, we list these
approaches here to safe others the work of investigating.

\begin{itemize}
    \item reimplement in Java
    \item use of a Galloping search before binary search
    \item unrolling the while-loop in \textit{LeapfrogTriejoin.moveToNextTuple}
    \item predicating the \textit{action} variable in \textit{LeapfrogTriejoin.moveToNextTuple}
\end{itemize}


% TODO future work?
Finally, we believe that code generation for specific queries that combines the functionality of \textit{LeapfrogTriejoin}, \textit{LeapfrogJoin}
and \textit{ArrayTrieIterator} into one query specific function would lead to noticeable performance improvements.
The reason for this believe is that our implementation takes about 3.46 for a trianlge query on the Twitter social circle dataset
while a triangle query specific Julia implementation, of a colleague of ours, needs only half a second.
The main difference between our implementation and his are: the language used (Julia is a high-performance, compile language) and the fact
that his his implementation has no query interpretation overhead but cannot handle any other query than the triangle query.

However, code generating a Leapfrog Triejoin is out of scope for this thesis, also, we are aware of efforts by RelationalAi to
write a paper about this specific topic.
We are looking forward to see their results.


% comparision to other work
% comparision to richards work

%  filter?
%    distinct filter does not help
%    but smaller than does - a lot

%  variable ordering

\subsection{User interface}\label{subsec:user-interface}
\begin{listing}[H]
    \inputminted{scala}{code/usage-example.scala}
    \caption{Example usage of a WCOJ to find triangles in graph.}
    \label{lst:usage-example}
\end{listing}

As one can see in line 16 % LINE
of~\cref{lst:usage-example}, we support a clean and precise DSL to match patterns in graphs.
This DSL is inspired by GraphFrames~\cite{graph-frames}.
The user can define a pattern by its edges, each edge is written as \textit{(a) - [] -> (b)} where \textit{a} is the
source vertice and \textit{b} is the destination, multiple edges are separated by a semicolon.
A connected pattern is expressed by defining multiple edges with the same source or destination.
One should be aware, that a named source or destination is not guaranteed to be a distinct element in the graph,
e.g. \textit{(a) - [] -> (b); (b) - [] -> (c)} could be a linear path of size two or a circle between \textit{a} and
\textit{b}; in the second case \textit{a} and \textit{c} are the same element.
The reader might wonders, why we chose to stay with the GraphFrame syntax for edges of
\textit{- [] ->}, although, we could have went with something simpler, like \textit{->}.
However, sticking to the more verbose syntax allows us to include labels inside of the squared brackets
in future extensions, e.g. for our stretch goal of integration with CAPS.

The second parameter to \textit{findPattern} allows the user to specify the variable ordering used in the WCOJ algorithm.
Furthermore, the user interface takes multiple optional arguments, e.g. to apply to common filters to the output of the result,
specify different relationships to be used as input for each edge of the pattern.
The filters are \textit{distinctFilter}, ensuring that each vertice can occur only as binding for one variable, and
\textit{smallerThanFilter} to allow only output bindings were the values decrease with regards to the specified variable ordering,
e.g. the binding \textit{[1, 2, 3]} but not \textit{[2, 1, 3]} for the triangle query above.
We experienced that these queries are typical for graph queries and that the performance greatly benefits from pushing
them into the join.
Implementing the possibility to push general filters into the join would be a valuable addition but we decided against it because
it a pure engineering task.


\subsection{Spark integration}\label{subsec:spark-integration}

% Logical operator => WCOJ
%   Attribute creation?
%   pattern parsing?
% Strategy => WCOJ2WCOJExec also generating the ToTrieIterableRDDExec children
% Physical operator => WCOJExec
%   general zip partitions?
% Physical operator, ToTrieIterableRDDExec
%    use ensure childOrdering to enforce sorting
%    builds a TrieIterableRDD which is an RDD with TrieIterable partitions
%    building these is a simple matter of adding all rows of each input RDD partition to one array as output partition
%    from this array I can use TrieIteratorImpl to iterate these arrays in a trie form as explained in ref

% JoinSpecification?  move to leapfrogJoin???
% patterns?  move to LeapfrogJoin???


\subsubsection{Graph pattern sequential version (\textit{graph-pattern-seq})}
