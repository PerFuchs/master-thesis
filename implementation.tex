\section{Implementation}\label{sec:implementation}

\subsection{General sequential version (\textit{seq})}\label{ssec:seq-implementation}


\subsubsection{Optimizations}
% TODO micro benchmark linear search
A simple, idiomatic Scala implementation of the Tributary join is not able to beat Spark's \texttt{BroadcastHashjoin} on any other query than the triangle query.
Hence, we spent roughly 2 weeks to optimize our first implementation.
After, we are able to beat Spark's \texttt{BroadcastHashjoin} on nearly all queries and datasets.
In this section, we discuss the implemented optimization and give a rough estimate of how important each of these is.
In total, we improved the WCOJ running time from 248.2 seconds to 44.5 seconds on the unfiltered 5-clique query on the
\texttt{Amazon-0602} dataset.
We list all optimizations in~\cref{table:optimizations-seq} and label them `very important', `important' and `minor' based on the performance improvement directly after applying it.

It is not helpful to give more detailed information on the effect of single optimization because they are not independent of each other.
Hence, they might have a hugely different effect when applied in a different order, e.g. we first applied an optimization to the binary search and then
optimized the \textit{LeapfrogJoin.next} method to avoid many searches
Hence, giving detailed runtime measurements for the binary search optimization would overestimate its value.
It is out of the scope of this work to study the dependency and order of the optimization to gain correct runtime measurements.

We discuss the optimization in categories: Leapfrog Triejoin specific, binary search specific, Spark related, Scala related and general.
We conclude the section with some changes we tried that do not improve performance.

Binary search specific optimizations become a category on its own because the sorted search is the most expensive operation in the Tributary join.
According to profiler sessions, the join spends more than 70\% of its time in this method. % TODO exact time
This result is in line with the observation that `in the Tributary join algorithm, the most expensive step is the binary search' from~\cite{myria-detailed}.

\begin{table}[]
\begin{tabular}{@{}lp{12cm}l@{}}
\toprule
Category                       & Optimization                                                                           & Impact         \\ \midrule
\multirow{2}{*}{\textbf{LFTJ}} & \textit{LeapfrogJoin.init} avoid sorting iterators                                               & very important \\
& \textit{ArrayTrieIterable.next} in $\mathcal{O} (1)$ for deepest level                               & very important \\
\hline
\multirow{2}{*}{\textbf{Binary search}} & linear search for short search spaces                                                  & important      \\
& avoiding unnecessary conditions                                                        & important      \\
\hline
\textbf{Spark}                  & direct use of arrays instead of \texttt{ColumnVector}                                           &
important

\\
\hline
\multirow{4}{*}{\textbf{Scala}}         & use \textit{while} instead of \textit{map}, \textit{foreach}, \textit{exists}, etc     & very important \\
& use \textit{Array} instead of Scala's collections                                      & very important \\
& use of \textit{private{[}this{]}}                                                      & minor          \\
& enable compiler optimization                                                           & minor          \\
\hline
\multirow{3}{*}{\textbf{General}}& remove array lookups from the critical path \textit{column(depth)(position) $\rightarrow$ currentColumn(position)} & very important \\
& use \textit{Array} instead of \textit{Map} if keys are integers and dense              & important      \\

& strength reduction \textit{(i + 1) \% 5} $\rightarrow$ \textit{if (i == 4) 0 else i+ 1}         & important      \\ \bottomrule

\end{tabular}
\caption{Summary of all optimizations used for \textit{seq} and an estimate of their impact. }
\label{table:optimizations-seq}
\end{table}

We applied two Tributary join specific optimizations.
The first in the class \texttt{leapfrogTriejoin.LeapfrogJoin} (see also~\cref{lst:leapfrog-join}) and the second
in the \texttt{leapfrogTriejoin.ArrayTrieIterable.TrieIteratorImpl}.

The \textit{LeapfrogJoin.init} method is origingally described in~\cite{leapfrog} to sort its \textit{TrieIterators}.
However, the method can be improved by avoiding to sort the \textit{TrieIterators} (line 11).  % LINE
We can start moving the \textit{TrieIterator} without sorting them and arrive at an ordered array in $\mathcal{O} (n)$ steps - $n$ defined as the size of \textit{iterators}.
This approach improves over the original algorithm in two ways: (1) it starts moving the \textit{TrieIterators} to their next intersection immediately without sorting them first and
(2) orders the array in fewer steps than traditional sorting algorithms.

To implement this we find the maximum \textit{key} value in all iterators and store the index of this \textit{TrieIterator} in \textit{p}.
Then we move the \textit{TrieIterator} at $p + 1$ to the least upper bound of this \textit{max} (by calling \textit{seek}) and store the result as the new maximum.
We proceed with this process - wrapping \textit{p} around when it reaches \textit{iterators.length} - until \textit{p} equals the original maximum index.
Now, we are either in a state in which all \textit{TrieIterators} point to the same value and we are done - the \textit{LeapfrogJoin} is initialized -
or we arrived at a state in which the \textit{iterators} array is sorted according to \textit{key} and can proceed as in the original \textit{LeapfrogJoin.init} method.
To apply this optimization one replaces the call to \textit{sort} in line 11 with the procedure explained above\footnote{The
implementation of Scala's array sort for objects is slow
because it copies the array twice and casts the values to \textit{Java.Object} such that it can use Java's sorting methods.
Before we applied the sorting optimization above, we replaced Scala's sort
method with an optimized insertion sort, which was faster than Scala's sorting method - the \textit{iterator} array contains normally at most 20 items.}.

The second Leapfrog Triejoin specific optimization is to change the \texttt{ArrayTrieIterable.TrieIteratorImpl.next} method.
This method moves the iterator to the next value on the same level of the trie.
Hence, it generally runs in $\mathcal{O} (\log n)$, $n$ being the number of tuples in the
relationship, because it needs to find the least upper bound of \textit{key + 1}.
However, under the assumption that all tuples are unique - which is fulfilled for the use-case of an edge relationship -
the last level of the trie is unique.
Hence, we can move to the next value by simply increasing the position by one, which is an operation in $\mathcal{O} (1)$.

The binary search is the most expensive operation of the Leapfrog Triejoin.
Hence, special attention needs to be paid while implementing it.
Our most important optimization is to change to a linear search once we narrowed the search space
to a certain threshold - currently at 60 values.
We experimented with values from 0 to 400 and found that 60 was optimal but even going as high as 120 values would not change the performance much.

Another important optimization is to avoid unnecessary if-statements in the loop of the binary
search, e.g. the implementation on Wikipedia and many other example implementations use an
if-statement with three branches for smaller, bigger and equal but two branches for greater than and less-or-equal suffice for a least upper bound search.

A similar optimization can be applied to a linear search on a sorted array: intuitively one would use the while-loop condition
\textit{array(i) > key $\wedge$ i < end} with \textit{key} being the key to find the least upper bound for, \textit{i} the loop invariant
and \textit{end} the exclusive end of the search space.
Anyhow, it is faster to check for \textit{key > array(end - 1)} once before the loop and return if this is the case because the value
cannot be found in the search space.
This obviously circumvents the main loop of the linear search;
additionally, it simplifies the loop condition to \textit{array(i) > key}.

The Spark infrastructure uses the interface \texttt{ColumnVector} to represent columns of relationships.
The implementation \texttt{OnHeapColumnVector} is a simple wrapper around an array of the correct type with support for \textit{null} values and \textit{append} operations.
First, we used this data structure to represent our columns but we could see a clear increase in performance by replacing it by an implementation that exposes the array
to allow the binary search to run on the array directly.
This is likely due to saving virtual function calls in the hottest part of our code.
The implementation is straightforward and can be found in our repository in \texttt{leapfrogTriejoin.ExposedArrayColumnVector}; we implemented it only for the \texttt{Long} datatype.

We found many standard optimizations and Scala specific optimizations to be really useful.
Most likely these are the optimizations that brought the biggest performance improvements.
However, they are well-known, so we mention them only in the~\cref{table:optimizations-seq}.
For Scala specific optimizations one can find good explanations at~\cite{databricks-scala-guide}.

Apart from the aforementioned very useful optimizations, we investigated multiple other avenues in hope for performance improvements
which did not succeed, we list these approaches here to save others the work of investigating:

\begin{itemize}
    \item reimplement in Java
    \item use of a Galloping search before the binary search
    \item unrolling the while-loop in \textit{LeapfrogTriejoin.moveToNextTuple}
    \item predicating the \textit{action} variable in \textit{LeapfrogTriejoin.moveToNextTuple}
\end{itemize}


% TODO future work?
Finally, we believe that code generation for specific queries that combines the functionality of \textit{LeapfrogTriejoin}, \textit{LeapfrogJoin}
and \textit{ArrayTrieIterator} into one query specific function would lead to noticeable performance improvements.
The reason for this belief is that our implementation takes about 3.46 seconds for a triangle query on the Twitter social circle dataset
while a triangle query specific Julia implementation, of a colleague of ours, needs only half a second.
The main difference between our implementation and his are: the language used (Julia is a high-performance, compiled language) and the fact
that his implementation has no query interpretation overhead but cannot handle any other query than the triangle query.

However, a code generated Leapfrog Triejoin is out of scope for this thesis, also, we are aware of efforts by RelationalAi to
write a paper about this specific topic.
We are looking forward to seeing their results.


% comparison to other work
% comparison to Richards work

%  filter?
%    distinct filter does not help
%    but smaller than does - a lot

%  variable ordering


