\section{Implementation}\label{sec:implementation}

\subsection{General sequential version (\textit{seq})}\label{subsec:general-sequential-version}
We implement the Leapfrog Triejoin~\cite{leapfrog} as our general sequential version of a WCOJ.
However, instead of using B-Trees as a backing data structure, we use sorted arrays and a binary search
to for its backing, which has been described in~\cite{myria-detailed} and is called Tributary join in their paper.
Our Leapfrog Triejoin is implemented in three components, which we explain in this order below: \textit{LeapfrogJoin}, \textit{ArrayTrieIterable} and
\textit{LeapfrogTriejoin}.

The Leapfrog join is a variant of the sort-merge join for unary relationships, original described in~\cite{leapfrog1,leapfrog2}. % TODO see LFTJ paper 4 and 7
To join $k$ unary relations $A_1(x)$, $A_2(x)$, \dots, $A_k(x)$ it takes one iterator per input relations and offers an iterator
interface that yields the intersection of all relations.
It requires that it's input iterators offer a \textit{key} method in $\mathcal{O}(1)$, a \textit{next} method and
a \textit{least\_upper\_bound(key: Int)} both in $\mathcal{O} (\log n)$ ($n$ defined as the size of the input relationship).
\textit{least\_upper\_bound} moves the iterator to the first position of the sought \textit{key} or the first position of the
next higher value.
An idiotmatic implementation of a Leapfrog join is shown in~\cref{lst:leapfrog-join}, for the optimized implementation see
\texttt{leapfrogTriejoin.LeapfrogJoin} in our repository.  % CODEREF

\begin{listing}[H]
    \inputminted{scala}{code/LeapfrogJoin.scala}
    \caption{Leapfrog join.}
    \label{lst:leapfrog-join}
\end{listing}

To support j-arity relations, $A(a_1, a_2, \dots, a_j)$ we add two methods to the iterator interface that represents the input
relationships: \textit{up} and \textit{down} both are required to work in $\mathcal{O} \log n$.
We call this new iterator \textit{Trieiteraor} because it represents the relationship as a trie, see~\cref{fig:trie-example}.

% TODO Trieiterator not in textit
The implementation of a \textit{Trieiterator} backed by a columnwise representation of the relation using one array
per column is straight forward, we outline the basic ideas next and refer to the interested reader to
\texttt{leapfrogTriejoin.ArrayTrieIterable.TrieIteratorImpl} in our repository for further details.  % CODEREF
It helps to think about the \textit{Trieiterator} as consisting out of a linear component, containing the functions
\textit{key}, \textit{next} and \textit{seek}, and horizontal component, made off the functions \textit{up} and \textit{down},
to move the linear component from one trie level to another.
First, we explain the horizontal component.
They keep track of the current \textit{level} of the \textit{Trieiterator} and the \textit{startPosition} and \textit{endPosition}
for in the columns,
e.g. in~\cref{fig:trie-example} when the current \textit{level} is 1 (or x) and the key equals 4 the \textit{startPosition} is 2 and
the \textit{endPosition} is 5 because the value 4 occurs 3 times.
With these bookkeeping variables, updated by \textit{up} and \textit{down}, one can implement the linear part by
a binary search over the current column (given by \textit{level}) which is limited to \textit{startPosition} and \textit{endPosition}.

\begin{figure}
    \centering
    \includesvg[height=5cm]{trie}
    \caption{A 3-ary relationship as table (left) and trie (right), to position the iterator at the tuple (1, 1, 5) one
    calls \textit{down} twice, \textit{key} returns now 5, after a call to \textit{next}, \textit{key} returns 6 and \textit{up}
    would lead to \textit{key} returning 1.}
    \label{fig:trie-example}
\end{figure}

The Leapfrog Triejoin combines \textit{Trieiterators} and Leapfrog joins to join $k$ relationships of arbitrary arity.
Its input is one \textit{Trieiterator} per relationship, from this it builds one Leapfrog join per attribute which
receives references to all \textit{Trieiterators} of relationships containing this attribute, e.g. for the triangle query
\textit{R(a, b), S(b, c), T(a, c)} the Leapfrog Triejoin receives three Trieiterators, for \textit{R}, \textit{S} and \textit{T},
and builds three Leapfrog joins, for $a$, $b$, $c$, which receive references to two TrieIterators each.
To generate the join result the Leapfrog Triejoin operates the horizontal components of the Trieiterators directly and
uses the Leapfrog joins to operate the linear component.

% TODO can I reference lines?
We show an idiomatic implementation in~\cref{lst:leapfrog-triejoin}, a performance oriented implementation can be found in our
repository in \texttt{leapfrogTriejoin.LeapfrogTriejoin}.
The listings contains two important functions: the initialization function from line TODO to line TODO % LINE
and the \textit{moveToNextTuple} function at line TODO. % LINE
We go through these functions in order.
The initializer gets two arguments: a mapping from variables to \textit{TrieIterators} (each \textit{TrieIterator} belongs to
the list of attributes of its relationship) and the global variable ordering as a list of \textit{Strings}.
First, it creates one \textit{LeapfrogJoin} per variable (line 2 to 9) which receives references % LINE
to each \textit{TrieIterator} operating on a relationship with this attribute; and builds a mapping from variables to
all \textit{TrieIterators} acting on a relationship with an attribute of the same name (line TOOD). % LINE
Then we initialize \textit{depth}, \textit{bindings} and \textit{atEnd} (line TODO to line TODO). % LINES
\textit{depth} and \textit{bindings} are an internal variable storing the index of the variable to bind currently and the
current bindings for all variables up to \textit{depth}.
\textit{atEnd} signals that the join has been completed to the client.
In line TODO, we move the join to the first tuple if it is not empty (line TODOff). % LINE
That means to move all \textit{TrieIterators} to their deepest level and storing the current binding for each level
in \textit{bindings}, so that these bindings are returned on the first call to \textit{next} - the join stores one output
tuples in bindings and returns it in \textit{next} after moving to the next tuple. % TODO change this in the implementation.

\textit{moveToNextTuple} implements a depth-first traversal of the intersection of the \textit{TrieIterators}.
This traversal needs to stop each time when a complete tuple has been found to support the iterator interface of the join.
Therefore, it is implemented as a state-machine which stops each time the deepest level is reached and all variables bound
(loop condition in line TODO). % LINE
The next action of the state machine is determined by the outcome of the current action variable.
Hence, we can characterize the state machine by describing each possible action and it's possible outcomes.
There are three possible actions: \textit{NEXT}, \textit{DOWN}, \textit{UP}.
We summarize the possible actions, conditions for the next action and
if the mainloop of the state machine yields the next tuple in~\cref{table:lftj-state-machine} and describe each action below.

First, \textit{NEXT} moves the \textit{LeapfrogJoin} at the current depth to the next possible binding for its variable (line TODO). % LINE
Then if \textit{LeapfrogJoin} reached its end, we continue with the \textit{UP} action (line TODO), % LINE
otherwise we set the binding and continue by the \textit{NEXT} action, if we are at the deepest level or by moving
to the next deeper level by the \textit{down} action (line TODO). % LINE
Second, \textit{DOWN} moves to the next variable in the global variable ordering by opening all related \textit{TrieIterators}
(line TODO) % LINE
A \textit{DOWN} can be followed by an \textit{UP} if the \textit{LeapfrogJoin} is \textit{atEnd} (line TODO),
by a \textit{NEXT} action if the trie join is at its lowest level (line TODO), or
by another \textit{DOWN} to reach the last level.
Finally, \textit{UP} can signal the completion of the join if all bindings for the first variable in the global ordering have
been explored, or in other words, the first \textit{LeapfrogJoin} is \textit{atEnd} (condition \textit{depth == 0 $\wedge$ action ==  UP\_ACTION} line TODO). % LINE
Otherwise, all \textit{TrieIterators} corresponding to the current variable are moved upwards
and \textit{depth} and \textit{bindings} updatd (lines TODO, TODO and TODO).  % LINE
Then, this action is followed by another \textit{UP} or a \textit{NEXT} depending on \textit{atEnd} of the current \textit{LeapfrogJoin} (lines TODO). % LINE
label \ref{myline}

\begin{table}[]
    \centering
    \begin{tabular}{@{}llll@{}}
        \toprule
        Action                & Condition                                  & Next action & Yields \\ \midrule
        \multirow{3}{*}{NEXT} & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd $\wedge$ reachedMaxDepth             & NEXT        & yes    \\
        & !lf.atEnd $\wedge$ !reachedMaxDepth            & DOWN        & no     \\
        & & &\\
        \multirow{3}{*}{DOWN} & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd $\wedge$ reachedMaxDepth             & NEXT        & yes    \\
        & !lf.atEnd $\wedge$ !reachedMaxDepth            & DOWN        & no     \\
        & & &\\
        \multirow{3}{*}{UP}     & depth == 0, means highest lf.atEnd is true & NA          & yes    \\
        & lf.atEnd                                   & UP          & no     \\
        & !lf.atEnd                                  & NEXT        & no     \\ \bottomrule
    \end{tabular}
    \caption{Summarizes which actions follow from the current action under certain conditions. \textit{lf} abbreviates the
    \textit{LeapfrogJoin} of the current variable.
    \textit{reachedMaxDepth} is true if we currently find bindings for the
    last variable in the global order.
    The columns \textit{Yields} details if the main loop of the state machine yields before computing the next action,
    this is the case, when \textit{bindings} contains a complete tuple.
    }
    \label{table:lftj-state-machine}
\end{table}
% TODO use the word open not down for the trieiterator

\begin{listing}[H]
    \inputminted[mathescape, linenos=true]{scala}{code/LeapfrogTriejoinIdiomatic.scala}
    \caption{Shows the main methods of \textit{LeapfrogTriejoin}, the initializer and \textit{moveToNextTuple} functionality
    helper methods are detailed in~\cref{lst:leapfrog-triejoin-helpers}.}
    \label{lst:leapfrog-triejoin}
\end{listing}

\begin{listing}[H]
    \inputminted{scala}{code/LeapfrogTriejoinHelpers.scala}
    \caption{\textit{LeapfrogTriejoin} helpers.}
    \label{lst:leapfrog-triejoin-helpers}
\end{listing}

\subsubsection{Optimizations}
A simple, idiomatic Scala implementation of the Tributary join is not able to beat Spark's \textit{BroadcastHashjoin} on any other query than the triangle query.
Hence, we spent roughly 2 weeks to optimize our first implementation.
After, we are able to beat Spark's \textit{BroadcastHashjoin} on nearly all queries and datasets.
In this section, we discuss the implemented optimization and give a rough estimate how important each of these are.
In total, we improved the WCOJ running time from 248.2 seconds to 44.5 seconds on the unfiltered 5-clique query on the
\textit{Amazon-0602} dataset.
We list all optimizations in~\cref{table:seq-optimizations} and label them `very important', `important' and `minor' based on the performance speedup encountered directly after applying it.
It is not helpful to give more detailed information on the effect of single optimization because they are not independ of each other.
Hence, they might have a hugely different effect when applied in different order, e.g. we first applied a optimization to the binary search of the arrays and then
optimized the \textit{LeapfrogJoin.next} method to avoid many of its searches, giving detailed runtime measurements for the binary search optimization would
overestimate its value.
It is out of scope of this work to study the dependency and ordering of the optimization to gain correct runtime measurements.

We discuss the optimization in categories in this order: Tributary join specific, binary search specific, Spark related, Scala related and general.
Binary search specific optimizations become a category on its own because the sorted search is the most expensive operation in the Tributary join.
According to profiler sessions the join spents more than 70\% of its time in this method. % TODO exact time
This result is in line with the observation that `in the Tributary join algorithm, the most expensive step is the binary search' from~\cite{myria-detailed}.

We applied to Tributary join specific optimizations one in the class \texttt{leapfrogTriejoin.LeapfrogJoin} (see also~\cref{lst:leapfrog-join}) and one
in the \texttt{leapfrogTriejoin.ArrayTrieIterable.TrieIteratorImpl}.
The \textit{LeapfrogJoin.init} method can be improve by avoiding to sort the \textit{TrieIterators} (line TODO)  % LINE
- the unoptimized implementation is described as such in the original Leapfrog Triejoin paper~\cite{leapfrog}.
However, we can start moving the \textit{TrieIterator} without sorting them and have them sorted in $\mathcal{O} \log n$ with $n$ the numbers of iterators.
This improves over sorting in two ways: (1) it starts moving the \textit{TrieIterators} to their next intersection immediately without sorting them first and
(2) it arrives at a sorted order in less steps than sorting.
For that we find the maximum \textit{key} value in all iterators and store the index of this \textit{TrieIterator} in \textit{p}.
Then we move the \textit{TrieIterator} at $p + 1$ to the least upper bound of this value (by calling \textit{seek}) and store the result as the new maximum.
We proceed with this process, with wrapping \textit{p} around when it reaches \textit{iterators.length}, until \textit{p} equals the original maximum index.
Now, we are either in a state in which all \textit{TrieIterators} point to the same value and we are done - the \textit{LeapfrogJoin} is initialized -
or we arrived at a state in which the array \textit{iterators} is sorted according to \textit{key} and can proceed as in the original \textit{LeapfrogJoin}.
To apply this optimization one replaces the call to \textit{sort} in line TODO with the procedure explained above~\footnote{The implementation of Scala's array sort for objects is really
slow because it copies the array twice and casts them to \textit{Java.object} to use Java's sorting methods. Before we applied the sorting optimization above, we replaced Scala's sort
method with an optimized insertion sort, which was way faster than Scala's sorting method - the \textit{iterator} array contains normally at most 20 items.}.




First, we can optimize the \textit{next} method.
This method moves the to the next value on the same level of the trie

% comparision to other work
% comparision to richards work


%  no use of scala collections and foreach, instead while and arrays (huge speedup)
%    removes casts but also use of direct lookup instead of hashing
%    no use of _.up
%    maps instead of linear lookups, then arrays instead of maps, then while looping instead of foreach
%  private[this] (minor speedup)
%  strength reduction of modulo (to ifs) and / 2 (speedup)
%  move indirections out of the critical path, like columns(depth).getInt(position(depth)) (huge speedup)

%  compiler optimizations (no big win)
%    which ones? inlining



% use of arrays directly instead of ColumnVector (huge speedup, avoids function calls in critical loop)

%  use linear search under threshold (experiments show that there is no big change in performance between 30 to 120 with peak for 60, and lower performance for 400 and 0) (huge speedup)
%  implement smallest possible version of lub and linear search, e.g. check pos < end only once, avoid third case in binary search (speedup)


%  no sorting
%   scala sort function is super expensive for small arrays, own insertion sort gives massive speedups (huge speedup)
%   no sorting at all (speedup)

%  next method optimization (huge speedup)


%  filter?
%    distinct filter does not help
%    but smaller than does - a lot

%  variable ordering







%  galloping search
%  state machine unrolling and predication not helpful
%  reimplement in java not helpful (see 03.05), tried with Galloping search, where according to a profiler most of the time is spent,
%  did not see improvement, given up

\subsection{User interface}\label{subsec:user-interface}
\begin{listing}[H]
    \inputminted{scala}{code/usage-example.scala}
    \caption{Example usage of a WCOJ to find triangles in graph.}
    \label{lst:usage-example}
\end{listing}

As one can see in line 16 % LINE
of~\cref{lst:usage-example}, we support a clean and precise DSL to match patterns in graphs.
This DSL is inspired by GraphFrames~\cite{graph-frames}.
The user can define a pattern by its edges, each edge is written as \textit{(a) - [] -> (b)} where \textit{a} is the
source vertice and \textit{b} is the destination, multiple edges are separated by a semicolon.
A connected pattern is expressed by defining multiple edges with the same source or destination.
One should be aware, that a named source or destination is not guaranteed to be a distinct element in the graph,
e.g. \textit{(a) - [] -> (b); (b) - [] -> (c)} could be a linear path of size two or a circle between \textit{a} and
\textit{b}; in the second case \textit{a} and \textit{c} are the same element.
The reader might wonders, why we chose to stay with the GraphFrame syntax for edges of
\textit{- [] ->}, although, we could have went with something simpler, like \textit{->}.
However, sticking to the more verbose syntax allows us to include labels inside of the squared brackets
in future extensions, e.g. for our stretch goal of integration with CAPS.

The second parameter to \textit{findPattern} allows the user to specify the variable ordering used in the WCOJ algorithm.
Furthermore, the user interface takes multiple optional arguments, e.g. to apply to common filters to the output of the result,
specify different relationships to be used as input for each edge of the pattern.
The filters are \textit{distinctFilter}, ensuring that each vertice can occur only as binding for one variable, and
\textit{smallerThanFilter} to allow only output bindings were the values decrease with regards to the specified variable ordering,
e.g. the binding \textit{[1, 2, 3]} but not \textit{[2, 1, 3]} for the triangle query above.
We experienced that these queries are typical for graph queries and that the performance greatly benefits from pushing
them into the join.
Implementing the possibility to push general filters into the join would be a valuable addition but we decided against it because
it a pure engineering task.


\subsection{Spark integration}\label{subsec:spark-integration}

% Logical operator => WCOJ
%   Attribute creation?
%   pattern parsing?
% Strategy => WCOJ2WCOJExec also generating the ToTrieIterableRDDExec children
% Physical operator => WCOJExec
%   general zip partitions?
% Physical operator, ToTrieIterableRDDExec
%    use ensure childOrdering to enforce sorting
%    builds a TrieIterableRDD which is an RDD with TrieIterable partitions
%    building these is a simple matter of adding all rows of each input RDD partition to one array as output partition
%    from this array I can use TrieIteratorImpl to iterate these arrays in a trie form as explained in ref

% JoinSpecification?  move to leapfrogJoin???
% patterns?  move to LeapfrogJoin???


\subsubsection{Graph pattern sequential version (\textit{graph-pattern-seq})}
